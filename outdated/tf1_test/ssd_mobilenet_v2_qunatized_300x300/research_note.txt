>>> 

==== .config ====
7
  =
  set
    train_config: {
      batch_size: 32
      data_augmentation_options {
        ssd_random_crop {
          operations {
            min_object_covered: 1.0
            min_aspect_ratio: 0.5
            max_aspect_ratio: 2.0
            min_area: 0.1
            max_area: 1.0
            overlap_thresh: 1.0
            random_coef: 0.0
          }
        }
      }
      data_augmentation_options {
        random_adjust_brightness {
        }
      }
      data_augmentation_options {
        random_adjust_contrast  {
        }
      }
      data_augmentation_options {
        random_adjust_saturation {
        }
      }
      data_augmentation_options {
        adjust_gamma {
          gamma: 0.7
        }
      }
      optimizer {
        momentum_optimizer {
          learning_rate: {
            exponential_decay_learning_rate {
              initial_learning_rate: 0.002
              decay_steps: 80000
              decay_factor: 0.95
              staircase: true
              burnin_learning_rate: 0.0
              burnin_steps: 0
              min_learning_rate: 0.0
            }
          }
          momentum_optimizer_value: 0.9
        }
      }
    }
    train_input_reader {
      tf_record_input_reader {
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_bagel.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_cheese_cake.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_croissant.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_fruit_cake.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_macaron.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_muffin.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_mug.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_scone.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_square_sandwich.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_takeout_hot.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_takeout_ice.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_tiramisu.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_triangle_sandwich.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_tumbler.record"
      }
      label_map_path: "/content/drive/MyDrive/shared_resource/annotations/my_label_map.pbtxt"
      shuffle: true
      # Buffer size to be used when shuffling file names. I set this as max of the number of each object class. 27*2*28
      filenames_shuffle_buffer_size: 1512
      # The number of weights must match the number of input files configured.
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.5
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.5
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.5
      sample_from_datasets_weights: 1.5
      sample_from_datasets_weights: 1.5
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.0
      sample_from_datasets_weights: 1.5
    }
  note
    0  > 114.>229.. 머야.. 언제마다 평가하는거지.. 한 에폭은 아닌데
    batch_size = 32로 했을 때 처음에 잘 돌아가다가, 40000 step 정도에서 OOM (Out of Memory) 이 발생한다. 코랩에서 램을 동적으로 할당하기 때문일수도?


6
  =
    DetectionBoxes_Precision/mAP = 0.7153152
    DetectionBoxes_Precision/mAP (large) = 0.7141131
    DetectionBoxes_Precision/mAP (medium) = 0.7294555
    DetectionBoxes_Precision/mAP (small) = -1.0
    DetectionBoxes_Precision/mAP@.50IOU = 0.93582755
    DetectionBoxes_Precision/mAP@.75IOU = 0.8827913
    DetectionBoxes_Recall/AR@1 = 0.7890046
    DetectionBoxes_Recall/AR@10 = 0.7890046
    DetectionBoxes_Recall/AR@100 = 0.7890046
    DetectionBoxes_Recall/AR@100 (large) = 0.78752315
    DetectionBoxes_Recall/AR@100 (medium) = 0.73333335
    DetectionBoxes_Recall/AR@100 (small) = -1.0
    Loss/classification_loss = 0.61666375
    Loss/localization_loss = 0.055913836
    Loss/regularization_loss = 0.32022092
    Loss/total_loss = 0.99279815
    global_step = 135813
    learning_rate = 0.0017147498
    loss = 0.99279815
  note
    [아예 다른 클래스의 score 가 최대치로 나온 경우, 맞는 클래스지만 score 가 너무 낮게 나온 경우]
      왜 비슷한 이미지를 반전시킨 이미지와 비슷한데 왜 분류를 잘못하지? 일반화를 위해서 클래스 밸런스를 맞추기위해, 회전, flip, flop 비율을 동일하게 맞추는 것이 중요.
      flip, flop, rotation90 확률을 다 0.5씩 줘봐야 하나? weight 가 이미지가 변경되지 않을 확률이 너무 높은듯. 다른 것과 밸런스를 맞추자. 
      threshold 0.5 이상의 validation map 가 낮게나와도 최대 score 만 일치하도록 하여 일반화시키는 것이 좋다.
    약간 각도가 회전된 이미지는 아예 다른 것으로 잡는 경우가 존재
      - https://github.com/JinLuckyboy/TensorFlowObjectDetectionAPI-with-imgaug
        Tensorflow Object detection API 는 각도회전은 90도만 가능하다. imgAug 를 연동한 옵션을 만들어서 generator 로 추가적으로 생성하자?
      - 일단은 [flip, flop] + optional rotation 0 ~ 90 (step: 15) 까지의 조합 경우의 수 28 개만큼 사진 한장마다 생성하여 훈련
        >> pipelin.config 의 random_image_sacle 옵션을 제거.
    물체에 노이즈를 black patch 가 아닌, 가로 또는 세로로 물체의 bounding box 의 모서리를 가리지 않도록 가로, 세로의 직사각형 노이즈를 합성.
      >> pipelin.config 의 random_black_patch 옵션을 제거.
    특정 물체의 클래스의 학습 weight 을 변경해야 하나?
      >> 일단 보류.
    Optimizer 를 SSD 에서 가장 validation rate 가 높게 나온다는 SGD 로 변경해보자.
    batch_size 와 클래스 수의 관계? 일단 32로 변경해보자.
  set
    train_input_reader {
      tf_record_input_reader {
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train.record"
        input_path: "/content/drive/MyDrive/shared_resource/annotations/train_with_natural_scene_1.record"
      }
    }
    eval_input_reader: {
        tf_record_input_reader {
        input_path: "/content/drive/MyDrive/shared_resource/annotations/test.record"
      }
    }
    optimizer {
          adam_optimizer ...
    }


5
  =
    Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.808
    Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000
    Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.993
    Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
    Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750
    Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.810
    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.839
    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.839
    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.839
    Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
    Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800
    Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.839
  note
    오분류 / 정상 분류 / 미포착 or 오포착
      tumbler:            0.00 / 0.67 / 0.33
      croissant:          0.00 / 0.33 / 0.67
      fruit_cake:         0.00 / 0.67 / 0.22
      square_sandwich:    0.00 / 0.50 / 0.50
      triangle_sandwich:  0.00 / 0.56 / 0.44
    정상 분류 0.66 미만의 공통점은 책상 색과 비슷하다는 점, 0.66 이상의 공통점은 색이 다채롭다는 점? 

    show_inference 로 확인해보니까 cam_02 는 100% 포착하고 100% True 인데 cam_01, cam_03 의 경우 아예 포착하지 못함.
      배경과 샌드위치, 크로와상 색이 비슷해서 confidence_rate (min_score) 가 0.5 를 못넘어서 표시가 안됬던 것.
      0.2 이상의 특징을 추출한 가장 높은 confidnece rate 물체를 분류 했을 때 최적의 결과를 얻었다. classification score 를 높이기 위해서 해야 할 일:
    배경을 합성해서 데이터 수와 다양성을 늘려보자.
      - [x]
        - GIMP로 물체를 제외하고 배경을 일일이 제거하고 다른 배경과 합성하기 vs scene image 다운로드받아서 조각조각을 붙여넣기
        - 포토샵 합성
      - 배경을 합성할 때 배경의 수만큼이 아니라, train_data 이미지 수만큼 랜덤으로 모두 적용되게 만들어보자.
        배경 이미지의 다양성도 중요하지만 각 클래스마다의 데이터 개수의 평균을 맞추는 것이 더 중요해 보임.
        각 클래스별 개수와 상관없이 배경개수만큼 합성하면 오버피팅이 될 수 있다.
      - 알파 블렌딩은 일단 보류
    각도별로 없는 데이터셋도 문제인거같음. 4방향 0 ~ 90 도 돌아가게 잘 맞춰서 찍었는데 테스트셋은 그 중 하나를 뽑아냈기 때문.
    pycoco eval 결과표는 medium 에 대해서가 아니라 IOU 0.5 이상의 정확도를 보도록 하자.
      정답을 맞춘 것들 중 실제 범위/모델이 예측한 범위 값의 평균 이라는 뜻. 때문에 IOU 가 높은 것이 정확도가 더 낮을수밖에.

  set
    train config {
      data_augmentation_options {
        random_horizontal_flip {
          probability: 0.2
        }
      }
      data_augmentation_options {
        random_vertical_flip  {
          probability: 0.2
        }
      }
      data_augmentation_options {
        random_rotation90 {
          probability: 0.2
        }
      }
      data_augmentation_options {
        random_image_scale {
        }
      }
      data_augmentation_options {
        ssd_random_crop {
        }
      }
      data_augmentation_options {
        random_adjust_brightness {
        }
      }
      data_augmentation_options {
        random_adjust_contrast  {
        }
      }
      data_augmentation_options {
        random_adjust_saturation {
        }
      }
      data_augmentation_options {
        adjust_gamma {
          gamma: 0.8
        }
      }
      data_augmentation_options {
        random_black_patches {
          probability: 0.25
          size_to_image_ratio: 0.01
        }
      }
    }


4
  =
    DetectionBoxes_Precision/mAP = 0.9847531
    DetectionBoxes_Precision/mAP (large) = 0.98721963
    DetectionBoxes_Precision/mAP (medium) = 0.93465346
    DetectionBoxes_Precision/mAP (small) = -1.0
    DetectionBoxes_Precision/mAP@.50IOU = 1.0
    DetectionBoxes_Precision/mAP@.75IOU = 1.0
    DetectionBoxes_Recall/AR@1 = 0.99012345
    DetectionBoxes_Recall/AR@10 = 0.99012345
    DetectionBoxes_Recall/AR@100 = 0.99012345
    DetectionBoxes_Recall/AR@100 (large) = 0.9916049
    DetectionBoxes_Recall/AR@100 (medium) = 0.95555556
    DetectionBoxes_Recall/AR@100 (small) = -1.0
    Loss/classification_loss = 0.006907619
    Loss/localization_loss = 0.0044285306
    Loss/regularization_loss = 0.2954235
    Loss/total_loss = 0.3067596
    global_step = 34847
    learning_rate = 0.004
    loss = 0.3067596
  note
    - 98.7 까지 올라갔었는데 과적합이 되어 다시 내려가버림. early stopping 을 찾거나 구현하는 것이 좋을듯.
      배경 이미지가 일관된 문제도 있는듯.
    - distort_color 문제로 케이크 종류를 오분류함.
    - early stop 이전에 checkpoint 를 계속 갱신하면서 마지막 체크포인트로부터 모델을 불러오며 학습하는 것이 문제.
      tf.estimator 에서는 best_loss_model 만 export 를 할 수는 있지만 best_checkpoint_loss 는 저장이 불가능한 것으로 확인됨.
  set
    train_config: {
      data_augmentation_options {
        random_distort_color {
        }
      random_horizontal_flip {
          probability: 0.25
        }
      }
      data_augmentation_options {
        random_vertical_flip  {
          probability: 0.25
        }
      }
      }
    }
  remove
    train_config: {
      data_augmentation_options {
        ssd_random_crop {
        }
      }
    }

3
  =
    DetectionBoxes_Precision/mAP = 0.800147
    DetectionBoxes_Precision/mAP (large) = 0.80147624
    DetectionBoxes_Precision/mAP (medium) = 0.7369233
    DetectionBoxes_Precision/mAP (small) = -1.0
    DetectionBoxes_Precision/mAP@.50IOU = 1.0
    DetectionBoxes_Precision/mAP@.75IOU = 0.98219043
    DetectionBoxes_Recall/AR@1 = 0.826875
    DetectionBoxes_Recall/AR@10 = 0.826875
    DetectionBoxes_Recall/AR@100 = 0.826875
    DetectionBoxes_Recall/AR@100 (large) = 0.82761574
    DetectionBoxes_Recall/AR@100 (medium) = 0.7722222
    DetectionBoxes_Recall/AR@100 (small) = -1.0
    Loss/classification_loss = 0.039221723
    Loss/localization_loss = 0.04637078
    Loss/regularization_loss = 0.30981448
    Loss/total_loss = 0.39540693
    global_step = 130874
    learning_rate = 0.004
    loss = 0.39540693
  note
    - mAP 75 ~ 80 에서 변동.
    - ssd_random_crop 을 하면 속도는 확실히 70 sec 이상에서 (32.747 sec) 로 빨라진다.
      ssd_random_crop 의 옵션을 현재 모델이 목적에 따라 조정해야 한다.
        현재 모델은 분류하려는 물체가 모두 보이므로, crop 의옵션에서 물체가 무조건 보이도록 추후 설정을 변경할 필요가 있음.
      ssd_random_crop 의 수치를 변경.
      
  set
    data_augmentation_options {
      ssd_random_crop {
      }
    }
  remove
    train_config: {
      data_augmentation_options {
        normalize_image {
          original_minval: 0.0
          original_maxval: 255.0
          target_minval: -1.0
          target_maxval: 1.0
          }
      }
    }

2
  =
    DetectionBoxes_Precision/mAP = 0.0018014528
    DetectionBoxes_Precision/mAP (large) = 0.0018014528
    DetectionBoxes_Precision/mAP (medium) = 0.0
    DetectionBoxes_Precision/mAP (small) = -1.0
    DetectionBoxes_Precision/mAP@.50IOU = 0.0074336557
    DetectionBoxes_Precision/mAP@.75IOU = 1.1004489e-05
    DetectionBoxes_Recall/AR@1 = 0.005532407
    DetectionBoxes_Recall/AR@10 = 0.011898148
    DetectionBoxes_Recall/AR@100 = 0.0148611115
    DetectionBoxes_Recall/AR@100 (large) = 0.0148611115
    DetectionBoxes_Recall/AR@100 (medium) = 0.0
    DetectionBoxes_Recall/AR@100 (small) = -1.0
    Loss/classification_loss = 21.643515
    Loss/localization_loss = 2.3632224
    Loss/regularization_loss = 0.2602663
    Loss/total_loss = 24.267006
    global_step = 72756
    learning_rate = 0.004
    loss = 24.267006
  note
    - ???
      normalize 적용 시, mAP 가 올라가지 않음. eval_config 에는 정규화 옵션 지정을 못해서 그런지, qunatized 모델의 문제인지 추후 확인 필요.
        from object_detection.core import preprocessor_test 에는 이렇게 되어있는데 이 차이일수도?
        'target_minval': 0,
        'target_maxval': 1
  set
    train_config: {
      data_augmentation_options {
        normalize_image {
          original_minval: 0.0
          original_maxval: 255.0
          target_minval: -1.0
          target_maxval: 1.0
          }
      }
    }


1
  =
    DetectionBoxes_Precision/mAP = 0.93719554
    DetectionBoxes_Precision/mAP (large) = 0.9388302
    DetectionBoxes_Precision/mAP (medium) = 0.87767565
    DetectionBoxes_Precision/mAP (small) = -1.0
    DetectionBoxes_Precision/mAP@.50IOU = 1.0
    DetectionBoxes_Precision/mAP@.75IOU = 1.0
    DetectionBoxes_Recall/AR@1 = 0.9532793
    DetectionBoxes_Recall/AR@10 = 0.9532793
    DetectionBoxes_Recall/AR@100 = 0.9532793
    DetectionBoxes_Recall/AR@100 (large) = 0.9545139
    DetectionBoxes_Recall/AR@100 (medium) = 0.89444447
    DetectionBoxes_Recall/AR@100 (small) = -1.0
    Loss/classification_loss = 0.008854638
    Loss/localization_loss = 0.010960821
    Loss/regularization_loss = 0.2941672
    Loss/total_loss = 0.31398344
    global_step = 34864
    learning_rate = 0.004
    loss = 0.31398344
  note
    - MAP is zero
      0 ~ 15k step 까지 mAP 가 0 에 가깝다.
    - Why so speed is slow
      The output will normally look like it has “frozen” after the loss for step 0 has been logged, but DO NOT rush to cancel the process. The training outputs logs only every 100 steps by default, therefore if you wait for a while, you should see a log for the loss at step 100.
      The time you should wait can vary greatly, depending on whether you are using a GPU and the chosen value for batch_size in the config file, so be patient.
    - 빠른 학습을 위해 정규화 augmentation normalize 추가 필요.
    - test dataset 이 적어서 높은 mAP 가 나왔을 것이라고 추정. augmentation 필요.
      - 검정색 쟁반 안에 검정색 물체가 담긴 물체를 일부 잡지 못함. (takeout_ice)
      - 검정색 쟁반 안의 크로와상을 일부 잡지 못함.
  set
    train_config: {
      batch_size: 8
    }

- augumenations options order
  not sensitive, but arrange in order

